{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69dd869",
   "metadata": {},
   "source": [
    "## Merge Cleaned Datasets and Deep Cleaning\n",
    "\n",
    "1. Load cleaned datasets (`IRENA`, `OWID CO₂`, `WGI`)\n",
    "2. Inspect each dataset for types, missing values, and column consistency\n",
    "3. Merge datasets step by step using `ISO3` and `year`\n",
    "4. Handle missing values (fill, drop, or keep as NA)\n",
    "5. Generate a final combined dataset ready for EDA and visualizations\n",
    "6. Save in /data/final folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3838b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import skew # type: ignore\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e713ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project setup: configure paths and imports for accessing modules and data files\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set project root\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Add project_root and project_scripts to sys.path for imports\n",
    "project_scripts = project_root / \"project_scripts\"\n",
    "for p in [project_root, project_scripts]:\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5774b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Setup and Imports \n",
    "from project_scripts import project_path_setup\n",
    "from project_scripts.data_handler import DataHandler\n",
    "\n",
    "# Project paths (from project_path_setup.py)\n",
    "project_root = project_path_setup.project_root\n",
    "project_scripts = project_path_setup.project_scripts\n",
    "\n",
    "# Data directories (relative paths from project_root)\n",
    "raw_dir = project_root / \"data\" / \"raw\"\n",
    "clean_dir = project_root / \"data\" / \"cleaned\"\n",
    "final_dir = project_root / \"data\" / \"final\"\n",
    "sqlite_dir = project_root / \"data\" / \"sqlite\"\n",
    "\n",
    "# Ensure directories exist\n",
    "for d in [clean_dir, final_dir, sqlite_dir]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Load datasets\n",
    "# #Initialize dataframes to avoid warnings\n",
    "irena: pd.DataFrame = None\n",
    "# owid: pd.DataFrame = pd.DataFrame()\n",
    "# wgi: pd.DataFrame = pd.DataFrame()\n",
    "# Load cleaned IRENA\n",
    "irena = pd.read_csv(clean_dir / \"irena_countries.csv\")\n",
    "print(\"IRENA shape:\", irena.shape)\n",
    "irena.head(2)\n",
    "\n",
    "# Load cleaned OWID\n",
    "owid = pd.read_csv(clean_dir / \"owid_countries.csv\")\n",
    "print(\"OWID shape:\", owid.shape)\n",
    "owid.head(2)\n",
    "\n",
    "# Load cleaned WGI\n",
    "wgi = pd.read_csv(clean_dir / \"wgi_countries.csv\")\n",
    "print(\"WGI shape:\", wgi.shape)\n",
    "wgi.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ff6e0",
   "metadata": {},
   "source": [
    "## Check key columns for merging\n",
    "We will merge datasets on:\n",
    "- `country_iso` → standardized ISO3 code\n",
    "- `year` → numeric year\n",
    "\n",
    "Check if these columns exist and have no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e431cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IRENA columns:\n",
      " ['region', 'sub-region', 'country', 'iso3_code', 'm49_code', 're_or_non-re', 'group_technology', 'technology', 'sub-technology', 'producer_type', 'year', 'electricity_generation_(gwh)', 'electricity_installed_capacity_(mw)', 'heat_generation_(tj)', 'public_flows_(2022_usd_m)', 'sdg_7a1_intl._public_flows_(2022_usd_m)', 'sdg_7b1_re_capacity_per_capita_(w/inhabitant)']\n",
      "\n",
      "OWID columns:\n",
      " ['country', 'year', 'iso_code', 'population', 'gdp', 'cement_co2', 'cement_co2_per_capita', 'co2', 'co2_growth_abs', 'co2_growth_prct', 'co2_including_luc', 'co2_including_luc_growth_abs', 'co2_including_luc_growth_prct', 'co2_including_luc_per_capita', 'co2_including_luc_per_gdp', 'co2_including_luc_per_unit_energy', 'co2_per_capita', 'co2_per_gdp', 'co2_per_unit_energy', 'coal_co2', 'coal_co2_per_capita', 'consumption_co2', 'consumption_co2_per_capita', 'consumption_co2_per_gdp', 'cumulative_cement_co2', 'cumulative_co2', 'cumulative_co2_including_luc', 'cumulative_coal_co2', 'cumulative_flaring_co2', 'cumulative_gas_co2', 'cumulative_luc_co2', 'cumulative_oil_co2', 'cumulative_other_co2', 'energy_per_capita', 'energy_per_gdp', 'flaring_co2', 'flaring_co2_per_capita', 'gas_co2', 'gas_co2_per_capita', 'ghg_excluding_lucf_per_capita', 'ghg_per_capita', 'land_use_change_co2', 'land_use_change_co2_per_capita', 'methane', 'methane_per_capita', 'nitrous_oxide', 'nitrous_oxide_per_capita', 'oil_co2', 'oil_co2_per_capita', 'other_co2_per_capita', 'other_industry_co2', 'primary_energy_consumption', 'share_global_cement_co2', 'share_global_co2', 'share_global_co2_including_luc', 'share_global_coal_co2', 'share_global_cumulative_cement_co2', 'share_global_cumulative_co2', 'share_global_cumulative_co2_including_luc', 'share_global_cumulative_coal_co2', 'share_global_cumulative_flaring_co2', 'share_global_cumulative_gas_co2', 'share_global_cumulative_luc_co2', 'share_global_cumulative_oil_co2', 'share_global_cumulative_other_co2', 'share_global_flaring_co2', 'share_global_gas_co2', 'share_global_luc_co2', 'share_global_oil_co2', 'share_global_other_co2', 'share_of_temperature_change_from_ghg', 'temperature_change_from_ch4', 'temperature_change_from_co2', 'temperature_change_from_ghg', 'temperature_change_from_n2o', 'total_ghg', 'total_ghg_excluding_lucf', 'trade_co2', 'trade_co2_share', 'country_iso']\n",
      "\n",
      "WGI columns:\n",
      " ['codeindyr', 'code', 'country', 'year', 'indicator', 'estimate', 'stddev', 'nsource', 'pctrank', 'pctranklower', 'pctrankupper', 'adb', 'afr', 'asd', 'bps', 'bti', 'ccr', 'ebr', 'eiu', 'eqi', 'frh', 'gcb', 'gcs', 'gii', 'gwp', 'her', 'hum', 'hrm', 'ifd', 'ijt', 'ipd', 'irp', 'lbo', 'msi', 'obi', 'pia', 'prc', 'prs', 'rsf', 'tpr', 'vab', 'vdm', 'wbs', 'wcy', 'wjp', 'wmo', 'scalemean', 'scalesd', 'country_iso']\n"
     ]
    }
   ],
   "source": [
    "#2. Inspect datasets\n",
    "#list view of column names\n",
    "print(\"\\nIRENA columns:\\n\", irena.columns.tolist()) # type: ignore\n",
    "print(\"\\nOWID columns:\\n\", owid.columns.tolist()) # type: ignore\n",
    "print(\"\\nWGI columns:\\n\", wgi.columns.tolist()) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7277fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing ISO3 codes and years\n",
    "# Check IRENA\n",
    "print(irena[['iso3_code','year']].isna().sum())\n",
    "# Check OWID\n",
    "print(owid[['iso_code','year']].isna().sum())\n",
    "# Check WGI\n",
    "print(wgi[['country_iso','year']].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1b4ff",
   "metadata": {},
   "source": [
    "datasets are clean, aligned, and ready to be merged using ISO code + year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ab8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Merge\n",
    "\n",
    "# 1. Standardize ISO column names in the 3 datasets\n",
    "# 2. Merge `IRENA` + `OWID` on `country_iso` and `year` (left join)\n",
    "# 3. Merge the result with `WGI` (left join)\n",
    "# 4. Keep all IRENA rows; missing OWID or WGI data will be NaN\n",
    "# Merge IRENA + OWID\n",
    "\n",
    "# Make ISO column consistent across datasets\n",
    "irena = irena.rename(columns={'iso3_code': 'iso'})\n",
    "owid  = owid.rename(columns={'iso_code': 'iso'})\n",
    "wgi   = wgi.rename(columns={'country_iso': 'iso'})\n",
    "# Merge IRENA + OWID\n",
    "irena_owid = pd.merge(\n",
    "    irena,\n",
    "    owid,\n",
    "    on=['iso','year'],\n",
    "    how='left',\n",
    "    suffixes=('_irena','_owid')\n",
    ")\n",
    "print(\"IRENA + OWID shape:\", irena_owid.shape)\n",
    "\n",
    "# Merge with WGI\n",
    "final_df = pd.merge(\n",
    "    irena_owid,\n",
    "    wgi,\n",
    "    on=['iso','year'],\n",
    "    how='left',\n",
    "    suffixes=('','_wgi')\n",
    ")\n",
    "print(\"Final merged shape:\", final_df.shape)\n",
    "#Save final dataset\n",
    "final_df.to_csv(\"../data/final/final_countries.csv\", index=False)\n",
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check Data Types\n",
    "# Show all columns without truncation\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# final_df.dtypes\n",
    "print(final_df.dtypes.to_frame('dtype').to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098997bf",
   "metadata": {},
   "source": [
    "Type Conversion Summary\n",
    "1.Many numeric columns (e.g., population, gdp, co2) are stored as object → need conversion to numeric for analysis.\n",
    "2.year is currently int64 → as is or converted to datetime for time-series operations.\n",
    "3.Columns like region, country names, and ISO codes are object → convert to category to save memory.\n",
    "\n",
    "Actions Taken\n",
    "1.Convert numeric columns stored as object → float64/int64.\n",
    "2.Convert year →  convert to datetime.\n",
    "3.Convert categorical columns (region, iso, country names, etc.) → category.\n",
    "\n",
    "Benefits\n",
    "1.Enables proper numeric calculations and aggregations.\n",
    "2.Optimizes memory usage.\n",
    "3.Prepares dataset for time-series and categorical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Convert numeric columns stored as object to numeric\n",
    "# List numeric columns that may be stored as object\n",
    "numeric_cols = [\n",
    "    'population', 'gdp', 'cement_co2', 'co2', 'co2_per_capita', 'coal_co2', 'oil_co2',\n",
    "    'gas_co2', 'methane', 'nitrous_oxide', 'primary_energy_consumption',\n",
    "    'electricity_generation_(gwh)', 'electricity_installed_capacity_(mw)',\n",
    "    'heat_generation_(tj)', 'public_flows_(2022_usd_m)',\n",
    "    'sdg_7a1_intl._public_flows_(2022_usd_m)',\n",
    "    'sdg_7b1_re_capacity_per_capita_(w/inhabitant)',\n",
    "    'temperature_change_from_co2', 'temperature_change_from_ch4', \n",
    "    'temperature_change_from_ghg', 'total_ghg', 'total_ghg_excluding_lucf',\n",
    "    'scalemean', 'scalesd'\n",
    "]\n",
    "\n",
    "# 2.Convert to numeric, coercing errors to NaN\n",
    "for col in numeric_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "        \n",
    "\n",
    "#Convert year column to datetime\n",
    "\n",
    "# Or convert to datetime for time-series operations\n",
    "final_df['year'] = pd.to_datetime(final_df['year'], format='%Y')\n",
    "\n",
    "#3.Convert ISO codes, country names, and categorical labels to category\n",
    "cat_cols = [\n",
    "    'region', 'sub-region', 'country_irena', 'iso', 're_or_non-re', \n",
    "    'group_technology', 'technology', 'sub-technology', 'producer_type',\n",
    "    'country_owid', 'country_iso'\n",
    "]\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].astype('category')\n",
    "\n",
    "print(final_df.dtypes.to_frame('dtype').to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc3164",
   "metadata": {},
   "source": [
    "## 5. Check Missing Values\n",
    "\n",
    "- Some countries or years may be missing OWID or WGI data\n",
    "- Decide on imputation or leave as NA\n",
    "- For numeric columns we can fill with 0 or median (depends on context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values count\n",
    "missing_counts = final_df.isna().sum().sort_values(ascending=False)\n",
    "missing_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique ISO codes in each dataset - ISO overlap\n",
    "irena_isos = set(irena['iso'].unique())\n",
    "owid_isos  = set(owid['iso'].unique())\n",
    "wgi_isos   = set(wgi['iso'].unique())\n",
    "\n",
    "# Countries in IRENA but missing in OWID\n",
    "missing_in_owid = irena_isos - owid_isos\n",
    "print(\"ISOs in IRENA but missing in OWID:\", missing_in_owid)\n",
    "\n",
    "# Countries in IRENA but missing in WGI\n",
    "missing_in_wgi = irena_isos - wgi_isos\n",
    "print(\"ISOs in IRENA but missing in WGI:\", missing_in_wgi)\n",
    "\n",
    "# Countries present in all three\n",
    "common_isos = irena_isos & owid_isos & wgi_isos\n",
    "print(\"Countries present in all three datasets:\", len(common_isos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed52ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year coverage\n",
    "print(\"IRENA years:\", sorted(irena['year'].unique()))\n",
    "print(\"OWID years:\", sorted(owid['year'].unique()))\n",
    "print(\"WGI years:\", sorted(wgi['year'].unique()))\n",
    "#summary table\n",
    "summary = pd.DataFrame({\n",
    "    'dataset': ['IRENA','OWID','WGI'],\n",
    "    'num_rows': [len(irena), len(owid), len(wgi)],\n",
    "    'num_iso': [len(irena_isos), len(owid_isos), len(wgi_isos)]\n",
    "})\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73a90e",
   "metadata": {},
   "source": [
    "#### 1 ISO standardization check\n",
    "* `Countries present in all three datasets: 178` \n",
    "* There are many ISOs in IRENA missing in OWID and WGI (like `MTQ`, `XLA`, `PRI` …).\n",
    "* This is expected because some codes might be Non-sovereign territories (e.g., `GLP`, `MYT`), Deprecated codes or placeholders (`XLA`, `XOC`) and Countries not present in all datasets\n",
    "#### 2 Year coverage\n",
    "* IRENA: 2000–2024\n",
    "* OWID: 1750–2024 (huge historical coverage)\n",
    "* WGI: 1996–2023\n",
    "* This mismatch in years explains why many columns in the final merged dataset have **NaNs**.\n",
    "#### 3 Summary table\n",
    "* IRENA: 235 ISOs\n",
    "* OWID: 218 ISOs\n",
    "* WGI: 189 ISOs\n",
    "* Only a subset of countries overlap fully → final merged dataset will have missing values for some countries and years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing heat_generation_(tj) column\n",
    "final_df['heat_generation_(tj)'].describe()\n",
    "\n",
    "missing_by_country = final_df[final_df['heat_generation_(tj)'].isna()].groupby('iso').size().sort_values(ascending=False)\n",
    "print(missing_by_country)\n",
    "\n",
    "# Calculate median heat generation per country\n",
    "median_by_country = final_df.groupby('iso')['heat_generation_(tj)'].median()\n",
    "\n",
    "# View top 10\n",
    "print(median_by_country.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Select the column\n",
    "heat = final_df['heat_generation_(tj)']\n",
    "\n",
    "# Drop missing values temporarily for analysis\n",
    "heat_nonan = heat.dropna()\n",
    "\n",
    "# Calculate basic stats\n",
    "mean_val = heat_nonan.mean()\n",
    "median_val = heat_nonan.median()\n",
    "std_val = heat_nonan.std()\n",
    "skewness = skew(heat_nonan)\n",
    "\n",
    "print(f\"Mean: {mean_val:.2f}\")\n",
    "print(f\"Median: {median_val:.2f}\")\n",
    "print(f\"Std Dev: {std_val:.2f}\")\n",
    "print(f\"Skewness: {skewness:.2f}\")\n",
    "\n",
    "# Group by country\n",
    "country_stats = final_df.groupby('iso')['heat_generation_(tj)'].agg(\n",
    "    count='count',\n",
    "    missing='size',\n",
    "    mean='mean',\n",
    "    median='median',\n",
    "    std='std',\n",
    "    skew=lambda x: skew(x.dropna())\n",
    ").reset_index()\n",
    "\n",
    "# Calculate missing values per country\n",
    "country_stats['missing'] = final_df.groupby('iso')['heat_generation_(tj)'].apply(lambda x: x.isna().sum()).values\n",
    "\n",
    "print(country_stats.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Make sure column name is clean\n",
    "final_df.columns = final_df.columns.str.strip()\n",
    "\n",
    "# Step 1: Check missing before\n",
    "print(\"Missing before:\", final_df['heat_generation_(tj)'].isna().sum())\n",
    "\n",
    "# Step 2: Impute per country; if all NaN, keep as NaN\n",
    "final_df['heat_generation_(tj)'] = final_df.groupby('iso')['heat_generation_(tj)'].transform(\n",
    "    lambda x: x.fillna(x.median()) if not x.isna().all() else x\n",
    ")\n",
    "\n",
    "# Step 3: Check missing after\n",
    "print(\"Missing after:\", final_df['heat_generation_(tj)'].isna().sum())\n",
    "\n",
    "# View top 10\n",
    "print(median_by_country.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bcfe9a",
   "metadata": {},
   "source": [
    "Handling Missing Values in Energy & Socioeconomic Data\n",
    "1.Energy Generation Columns\n",
    "heat_generation_(TJ), electricity_generation_(GWh), electricity_installed_capacity_(MW)\n",
    "Fill missing values per country using median. If all values for a country are missing, leave as NaN.\n",
    "\n",
    "2.Population & GDP Columns\n",
    "population, gdp\n",
    "Fill missing values using interpolation along time for the same country. Avoid filling with 0 to prevent distortion in per-capita metrics.\n",
    "\n",
    "3.Derived / Aggregate Columns\n",
    "co2_per_capita, sdg_7b1_re_capacity_per_capita, trade_co2_share, etc.\n",
    "Recalculate after filling the raw data, or fill missing using country-wise median if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f353a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Imputation\n",
    "#Part 1: Energy Generation Columns\n",
    "# Ensure column names are clean\n",
    "final_df.columns = final_df.columns.str.strip()\n",
    "\n",
    "energy_cols = [\n",
    "    'heat_generation_(tj)',\n",
    "    'electricity_generation_(gwh)',\n",
    "    'electricity_installed_capacity_(mw)'\n",
    "]\n",
    "\n",
    "# Impute missing values per country using median\n",
    "for col in energy_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df.groupby('iso')[col].transform(\n",
    "            lambda x: x.fillna(x.median()) if not x.isna().all() else x\n",
    "        )\n",
    "\n",
    "# Check missing after\n",
    "print(\"Missing values after imputing energy columns:\")\n",
    "print(final_df[energy_cols].isna().sum())\n",
    "\n",
    "#Part 2: Population & GDP Columns\n",
    "pop_gdp_cols = ['population', 'gdp']\n",
    "\n",
    "# Interpolate missing values along time per country using transform\n",
    "for col in pop_gdp_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df.groupby('iso')[col].transform(\n",
    "            lambda x: x.interpolate(method='linear', limit_direction='both')\n",
    "        )\n",
    "\n",
    "# Check missing after\n",
    "print(\"Missing values after imputing population & GDP:\")\n",
    "print(final_df[pop_gdp_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bfef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute heat_generation_(tj) based on Energy generated columns\n",
    "# Energy columns\n",
    "installed_col = 'electricity_installed_capacity_(mw)'\n",
    "generation_col = 'electricity_generation_(gwh)'\n",
    "heat_col = 'heat_generation_(tj)'\n",
    "\n",
    "# For rows where heat_generation is missing but some electricity data exists\n",
    "mask = final_df[heat_col].isna() & (\n",
    "    final_df[installed_col].notna() | final_df[generation_col].notna()\n",
    ")\n",
    "\n",
    "# Fill with a small fraction of electricity generation or capacity as a proxy\n",
    "# Here we assume 1% of generation as a small placeholder\n",
    "final_df.loc[mask, heat_col] = final_df.loc[mask, generation_col].fillna(0) * 0.01\n",
    "\n",
    "print(\"Missing heat_generation_(tj) after related-column imputation:\", \n",
    "      final_df[heat_col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Derived / Aggregate Columns\n",
    "# ==============================\n",
    "derived_cols = [\n",
    "    'co2_per_capita', \n",
    "    'sdg_7b1_re_capacity_per_capita_(w/inhabitant)',\n",
    "    'trade_co2_share',\n",
    "    'cumulative_other_co2'\n",
    "]\n",
    "\n",
    "print(\"Missing values before imputing derived columns:\")\n",
    "print(final_df[derived_cols].isna().sum())\n",
    "\n",
    "for col in derived_cols:\n",
    "    if col in final_df.columns:\n",
    "        #Impute per country median if all values not missing\n",
    "        final_df[col] = final_df.groupby('iso')[col].transform(\n",
    "            lambda x: x.fillna(x.median()) if not x.isna().all() else x\n",
    "        )\n",
    "\n",
    "print(\"Missing values after imputing derived columns:\")\n",
    "print(final_df[derived_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Quick Descriptive Stats\n",
    "display(HTML(final_df.describe(include='all').T.to_html(max_rows=None, max_cols=None)))\n",
    "# Then display the transposed describe\n",
    "#final_df.describe(include='all').T\n",
    "#final_df.describe(include='all').T.head(10)\n",
    "#save to csv file\n",
    "final_df.describe(include='all').T.to_csv('describe_summary_final_merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Save final merged dataset\n",
    "final_path = final_dir / \"final_combined.csv\"\n",
    "final_df.to_csv(final_path, index=False)\n",
    "print(\"Saved final dataset:\", final_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
